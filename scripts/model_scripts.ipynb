{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST SCRIPT TO AUGMENT EACH IMAGE BY ROTATING 3 DIFFERENT WAYS; TO BE RUN IN PARALLEL IN BASH\n",
    "\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# Define the argument parser; takes two arguments - path to jpeg, and output prefix which will be appended with rotation and .jpeg\n",
    "parser = argparse.ArgumentParser(description='Transform an image and save the transformed images.')\n",
    "parser.add_argument('input_path', type=str, help='Path to the input JPEG file.')\n",
    "parser.add_argument('output_prefix', type=str, help='Prefix to use for output filenames.')\n",
    "\n",
    "# Parse the arguments\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Load the input image\n",
    "with Image.open(args.input_path) as im:\n",
    "    \n",
    "    # Crop the right-hand third of the image vertically, because it is all black in all images\n",
    "    width, height = im.size\n",
    "    cropped_im = im.crop((0, 0, width - width // 3, height))\n",
    "\n",
    "    # Resize the cropped image to 800x800\n",
    "    resized_im = cropped_im.resize((800, 800))\n",
    "\n",
    "    # Save the original transformed image\n",
    "    resized_im.save(args.output_prefix + '_orig.jpg')\n",
    "\n",
    "    # Create 3 additional rotated images and save them\n",
    "    for angle in [90, 180, 270]:\n",
    "        rotated_im = resized_im.rotate(angle)\n",
    "        output_path = args.output_prefix + f'_{angle}.jpg'\n",
    "        rotated_im.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d834c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECOND SCRIPT, TO PROCESS THE DATA, SET UP THE TENSORS, AND WRITE THE TENSORS TO DISK AS NUMPY BINARIES\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from sys import stderr\n",
    "\n",
    "print('Reading patient data...',file=stderr)\n",
    "\n",
    "patient_data = pd.read_excel('CMMD_clinicaldata_revision.xlsx',index_col='ID1')\n",
    "patient_data.index += patient_data.LeftRight\n",
    "\n",
    "all_data = defaultdict(dict)\n",
    "\n",
    "# Iterate over the data frame and collect values associated with patient ID keys\n",
    "for pat_id in patient_data.index:\n",
    "    if 'D2' in pat_id: # Skip D2 patient IDs as they are a different dataset\n",
    "        continue\n",
    "    all_data[pat_id]['calc'] = 1 if patient_data.abnormality[pat_id] != 'mass' else 0\n",
    "    all_data[pat_id]['mass'] = 1 if patient_data.abnormality[pat_id] != 'calcification' else 0\n",
    "    all_data[pat_id]['classification'] = 1 if patient_data.classification[pat_id] == 'Malignant' else 0\n",
    "    \n",
    "# Free up memory\n",
    "del patient_data\n",
    "\n",
    "print('Reading image data...',file=stderr)\n",
    "\n",
    "# Change to directory with augmented images\n",
    "os.chdir('Augmented')\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Iterate over all jpegs in directory and load them\n",
    "for fname in os.listdir(os.getcwd()):\n",
    "    if fname.split('.')[-1].lower() in ('.jpg','.jpeg'):\n",
    "        continue\n",
    "    count += 1\n",
    "    print(f'\\r{count}',end='')\n",
    "    pat_id = ''.join(fname.split('.')[:2])\n",
    "    img = Image.open(fname) # Load image\n",
    "    img = np.array(img) # Convert to 2D array\n",
    "    img = img.astype(np.float16) # Convert to 16bit float\n",
    "    img /= 255 # Min/max normalizes pixel brightness values, which range from 0-255\n",
    "    view = 'img_side' if '.S' in fname else 'img_top'\n",
    "    rotation = fname.split('_')[-1].split('.')[0] # Value will be 90, 180, 270, or orig\n",
    "    view += f'_{rotation}' # Values will be img_{side/top}_{90/180/270/orig}\n",
    "    all_data[pat_id][view] = img # Add 2D array of min/max normalized pixel values to patient data dict\n",
    "\n",
    "# Convert all_data to a dataframe\n",
    "all_data_df = pd.DataFrame(all_data).T # Transpose so rows are patients\n",
    "\n",
    "# Free up memory\n",
    "del all_data\n",
    "\n",
    "print('\\nSetting up tensors...',file=stderr)\n",
    "\n",
    "# For side images and top images, concatenate all rotations, in the same order\n",
    "side_img_concat = pd.concat([all_data_df.img_side_orig, all_data_df.img_side_90, all_data_df.img_side_180, all_data_df.img_side_270])\n",
    "top_img_concat = pd.concat([all_data_df.img_top_orig, all_data_df.img_top_90, all_data_df.img_top_180, all_data_df.img_top_270])\n",
    "\n",
    "# Create stacked numpy arrays out of the concatenated images\n",
    "side_img_tensor = np.stack(side_img_concat)\n",
    "top_img_tensor = np.stack(top_img_concat)\n",
    "\n",
    "# Repeat the labels 4x to account for the four rotations; label order will match\n",
    "labels = np.repeat(all_data_df[['calc','mass','classification']].to_numpy().astype(np.float16), 4, axis=0)\n",
    "\n",
    "# Print shape and data type of all tensors just to check for correctness\n",
    "print('\\nShapes:',file=stderr)\n",
    "for x in [side_img_tensor,top_img_tensor]:\n",
    "    print(x.shape,file=stderr)\n",
    "print(labels.shape,file=stderr)\n",
    "    \n",
    "print('\\nDTypes:',file=stderr)\n",
    "for x in [side_img_tensor,top_img_tensor]:\n",
    "    print(x.dtype,file=stderr)\n",
    "print(labels.dtype,file=stderr)\n",
    "\n",
    "# Get permuted indices to shuffle the tensors maintaining associations\n",
    "num_samples = side_img_tensor.shape[0] # First value in shape is number of samples\n",
    "permuted_indices = np.random.permutation(num_samples) # Shuffled array of ints from zero to num_samples\n",
    "\n",
    "# use the permuted indices to shuffle all three arrays in the same way\n",
    "side_img_tensor = side_img_tensor[permuted_indices]\n",
    "top_img_tensor = top_img_tensor[permuted_indices]\n",
    "labels = labels[permuted_indices]\n",
    "\n",
    "# Save numpy binaries\n",
    "np.save('../side_images.npy',side_img_tensor)\n",
    "np.save('../top_images.npy',top_img_tensor)\n",
    "np.save('../labes.npy',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIRD SCRIPT, TO READ IN THE NUMPY BINARIES, AND SET UP AND TRAIN THE MODEL\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, History\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Concatenate, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sys import argv, stderr\n",
    "\n",
    "# Script accepts one argument, an integer in (0,1,2) representing which single label to use\n",
    "which = int(argv[1])\n",
    "outname = [ 'calc', 'mass', 'malignant' ][which]\n",
    "\n",
    "print('Reading the tensors from disk...',file=stderr)\n",
    "\n",
    "# Read all numpy binaries\n",
    "side_img_tensor = np.load('side_images.npy')\n",
    "top_img_tensor = np.load('top_images.npy')\n",
    "labels = np.load('labes.npy')\n",
    "\n",
    "# Getting just one of the 3 labels, since training 3 non-mutually exclusive labels gave issues\n",
    "labels = labels[:, which].reshape(-1, 1)\n",
    "\n",
    "# Calculate and print the mean value of the labels, which also represents the proportion of 1's vs 0's (0.50 = equal split)\n",
    "mean_label = np.mean(labels)\n",
    "print(f'Label mean: {mean_label}')\n",
    "\n",
    "print('Setting up training and validation sets...',file=stderr)\n",
    "\n",
    "# Calculate the index representing an 80:20 split of the data points\n",
    "split_point = int(round(side_img_tensor.shape[0] * 0.80))\n",
    "\n",
    "# Split the data; x_train and x_val are two element lists, the elements being side and top image tensors\n",
    "x_train = [side_img_tensor[:split_point],top_img_tensor[:split_point]]\n",
    "x_val = [side_img_tensor[split_point:],top_img_tensor[split_point:]]\n",
    "y_train = labels[:split_point]\n",
    "y_val = labels[split_point:]\n",
    "\n",
    "print('Shapes:',file=stderr)\n",
    "for x in [x_train,x_val]:\n",
    "    for t in x:\n",
    "        print(t.shape,file=stderr)\n",
    "\n",
    "for y in [y_train,y_val]:\n",
    "    print(y.shape,file=stderr)\n",
    "    \n",
    "print('\\nDTypes:',file=stderr)\n",
    "for x in [x_train,x_val]:\n",
    "    for t in x:\n",
    "        print(t.dtype,file=stderr)\n",
    "\n",
    "for y in [y_train,y_val]:\n",
    "    print(y.dtype,file=stderr)\n",
    "\n",
    "print('\\nSetting up the model...',file=stderr)\n",
    "\n",
    "# NETWORK STARTS WITH 2 INPUTS, 2 PATHS\n",
    "\n",
    "# Define input layers\n",
    "side_view_input = Input(shape=(800, 800, 1), name='input_image_side')\n",
    "top_view_input = Input(shape=(800, 800, 1), name='input_image_top')\n",
    "\n",
    "# First convolutional layers for both images\n",
    "side_conv_1 = Conv2D(32, kernel_size=(8,8), strides=2, padding='same', activation='relu')(side_view_input)\n",
    "top_conv_1 = Conv2D(32, kernel_size=(8,8), strides=2, padding='same', activation='relu')(top_view_input)\n",
    "\n",
    "# Pooling layer receives a tensor that is 400x400, and outputs 200x200\n",
    "side_pool_1 = MaxPooling2D(pool_size=(2,2),padding='same')(side_conv_1)\n",
    "top_pool_1 = MaxPooling2D(pool_size=(2,2),padding='same')(top_conv_1)\n",
    "\n",
    "# EACH PATH BRANCHES HERE, FOR FOUR PATHS\n",
    "\n",
    "# Second convolution layer A - 5x5 filters\n",
    "side_conv_2A = Conv2D(32, kernel_size=(5,5), strides=2, padding='same', activation='relu')(side_pool_1)\n",
    "top_conv_2A = Conv2D(32, kernel_size=(5,5), strides=2, padding='same', activation='relu')(top_pool_1)\n",
    "\n",
    "# Second convolution layer B - 10x10 filters\n",
    "side_conv_2B = Conv2D(32, kernel_size=(10,10), strides=2, padding='same', activation='relu')(side_pool_1)\n",
    "top_conv_2B = Conv2D(32, kernel_size=(10,10), strides=2, padding='same', activation='relu')(top_pool_1)\n",
    "\n",
    "# Global max pooling layer for both images (alternative to flattening, reduces size to number of filters)\n",
    "side_global_pool_A = GlobalMaxPooling2D()(side_conv_2A)\n",
    "side_global_pool_B = GlobalMaxPooling2D()(side_conv_2B)\n",
    "top_global_pool_A = GlobalMaxPooling2D()(top_conv_2A)\n",
    "top_global_pool_B = GlobalMaxPooling2D()(top_conv_2B)\n",
    "\n",
    "# THE FOUR NETWORK PATHS CONVERGE TO ONE HERE\n",
    "\n",
    "# Merge flattened image layers and other features\n",
    "merged = Concatenate()([side_global_pool_A,side_global_pool_B,top_global_pool_A,top_global_pool_B])\n",
    "\n",
    "# Output layer\n",
    "output = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# model = Model(inputs=[side_view_input,top_view_input,features_input],outputs=output)\n",
    "model = Model(inputs=[side_view_input,top_view_input],outputs=output)\n",
    "\n",
    "# Add L2 regularization to all layers capable of regularization (hasattr kernel_regularizer)\n",
    "reg = regularizers.l1(0.01)\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, 'kernel_regularizer'):\n",
    "        layer.kernel_regularizer = reg     \n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "best_model_checkpoint = ModelCheckpoint(f'best_model_{outname}.h5', monitor='val_accuracy', save_best_only=True, save_weights_only=False, mode='max')\n",
    "history = History()\n",
    "\n",
    "print('Training the model...',file=stderr)\n",
    "\n",
    "model.fit(x=x_train, y=y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          epochs=50, batch_size=100, callbacks=[best_model_checkpoint, history])\n",
    "\n",
    "\n",
    "# Save the training history to disk\n",
    "with open(f'history_{outname}.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
